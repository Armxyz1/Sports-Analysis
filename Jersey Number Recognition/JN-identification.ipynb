{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1L1shvC7ZyW1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CymhUYhwZ3MI",
    "outputId": "f89683d2-90a5-46ba-b264-b166d333717b"
   },
   "outputs": [],
   "source": [
    "!pip install SoccerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6pZGicdZ4-b",
    "outputId": "134f8b5b-6651-460e-f2f0-c9638b241601"
   },
   "outputs": [],
   "source": [
    "# Mount to google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZHMHE8paMkm",
    "outputId": "0381390c-370d-4b91-d312-9af412d18c7d"
   },
   "outputs": [],
   "source": [
    "from SoccerNet.Downloader import SoccerNetDownloader as SNdl\n",
    "mySNdl = SNdl(LocalDirectory=\"path/to/SoccerNet\")\n",
    "mySNdl.downloadDataTask(task=\"jersey-2023\", split=[\"train\",\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4f-vd5paQae",
    "outputId": "1c5bc1f0-066c-41ca-b011-67add3bf74c2"
   },
   "outputs": [],
   "source": [
    "# Extract the zip file to drive\n",
    "!unzip /content/path/to/SoccerNet/jersey-2023/test.zip -d /content\n",
    "!unzip /content/path/to/SoccerNet/jersey-2023/train.zip -d /content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVe6jYVsaUPE",
    "outputId": "25c832af-c644-47fa-87cf-20929e14f296"
   },
   "outputs": [],
   "source": [
    "## Go through json file and figure out the unique classes\n",
    "\n",
    "classes = []\n",
    "with open(\"/home/sahilc/Sports-Analysis/Jersey Number Recognition/train/train_gt.json\") as f:\n",
    "    data = json.load(f)\n",
    "    for img_path, number in data.items():\n",
    "        classes.append(number)\n",
    "classes = list(set(classes))\n",
    "num_classes = len(classes)\n",
    "print(classes)\n",
    "print(num_classes)\n",
    "\n",
    "## Test it for test.json\n",
    "with open(\"/home/sahilc/Sports-Analysis/Jersey Number Recognition/test/test_gt.json\") as f:\n",
    "    data = json.load(f)\n",
    "    for img_path, number in data.items():\n",
    "        classes.append(number)\n",
    "classes = list(set(classes))\n",
    "num_classes = len(classes)\n",
    "print(classes)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_bUycoIEcZCv"
   },
   "outputs": [],
   "source": [
    "class JerseyNumberDataset(Dataset):\n",
    "    def __init__(self, root_dir, json_path, transform=None, is_train=True, number_mapping=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Directory containing the images folder\n",
    "            json_path (str): Path to the ground truth JSON file\n",
    "            transform: Optional transform to be applied on images\n",
    "            is_train (bool): If True, performs data augmentation\n",
    "            number_mapping (dict): Optional mapping from jersey numbers to class indices\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "\n",
    "        # Load annotations\n",
    "        print(f\"Loading annotations from {json_path}\")\n",
    "        with open(json_path, 'r') as f:\n",
    "            self.annotations = json.load(f)\n",
    "\n",
    "        # Create samples list\n",
    "        self.samples = []\n",
    "        images_dir = os.path.join(root_dir, \"images\")\n",
    "\n",
    "        print(f\"Looking for images in {images_dir}\")\n",
    "        if not os.path.exists(images_dir):\n",
    "            raise ValueError(f\"Images directory not found at {images_dir}\")\n",
    "\n",
    "        # Get all valid image paths and their labels\n",
    "        all_numbers = set()\n",
    "\n",
    "        # Handle nested directory structure\n",
    "        for img_path, number in self.annotations.items():\n",
    "            player_dir = os.path.join(images_dir, img_path)\n",
    "            if os.path.isdir(player_dir):\n",
    "                # If it's a directory, get all images inside it\n",
    "                for img_file in os.listdir(player_dir):\n",
    "                    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        full_path = os.path.join(player_dir, img_file)\n",
    "                        all_numbers.add(number)\n",
    "                        self.samples.append({\n",
    "                            'img_path': full_path,\n",
    "                            'number': number\n",
    "                        })\n",
    "            elif os.path.isfile(player_dir) and player_dir.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                # If it's directly an image file\n",
    "                all_numbers.add(number)\n",
    "                self.samples.append({\n",
    "                    'img_path': player_dir,\n",
    "                    'number': number\n",
    "                })\n",
    "\n",
    "        # Create number to index mapping if not provided\n",
    "        if number_mapping is None:\n",
    "            sorted_numbers = sorted(list(all_numbers))\n",
    "            self.number_to_idx = {num: idx for idx, num in enumerate(sorted_numbers)}\n",
    "        else:\n",
    "            self.number_to_idx = number_mapping\n",
    "\n",
    "        print(f\"Found {len(self.samples)} valid images\")\n",
    "        if len(self.samples) == 0:\n",
    "            raise ValueError(f\"No valid samples found in {images_dir}\")\n",
    "\n",
    "        # Print class distribution\n",
    "        numbers = [sample['number'] for sample in self.samples]\n",
    "        class_dist = {}\n",
    "        for num in numbers:\n",
    "            class_dist[num] = class_dist.get(num, 0) + 1\n",
    "        print(\"\\nClass distribution:\")\n",
    "        for num, count in sorted(class_dist.items()):\n",
    "            print(f\"Number {num}: {count} samples ({count/len(numbers)*100:.2f}%)\")\n",
    "\n",
    "        print(\"\\nClass mapping:\")\n",
    "        for num, idx in sorted(self.number_to_idx.items()):\n",
    "            print(f\"Jersey number {num} -> Class index {idx}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "\n",
    "        try:\n",
    "            image = Image.open(sample['img_path']).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {sample['img_path']}: {str(e)}\")\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        target = self.number_to_idx[sample['number']]\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XDe6_egd9O7"
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_datasets(train_dir, test_dir):\n",
    "    \"\"\"Create train and validation datasets with consistent class mapping\"\"\"\n",
    "    # First, gather all possible numbers from both train and test sets\n",
    "    all_numbers = set()\n",
    "\n",
    "    # From training set\n",
    "    with open(os.path.join(train_dir, 'train_gt.json'), 'r') as f:\n",
    "        train_annotations = json.load(f)\n",
    "        all_numbers.update(train_annotations.values())\n",
    "\n",
    "    # From test set\n",
    "    with open(os.path.join(test_dir, 'test_gt.json'), 'r') as f:\n",
    "        test_annotations = json.load(f)\n",
    "        all_numbers.update(test_annotations.values())\n",
    "\n",
    "    # Create mapping\n",
    "    sorted_numbers = sorted(list(all_numbers))\n",
    "    number_mapping = {num: idx for idx, num in enumerate(sorted_numbers)}\n",
    "\n",
    "    print(f\"\\nTotal unique jersey numbers found: {len(number_mapping)}\")\n",
    "\n",
    "    # Data transforms\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Create datasets with shared mapping\n",
    "    train_dataset = JerseyNumberDataset(\n",
    "        root_dir=train_dir,\n",
    "        json_path=os.path.join(train_dir, 'train_gt.json'),\n",
    "        transform=train_transform,\n",
    "        number_mapping=number_mapping\n",
    "    )\n",
    "\n",
    "    val_dataset = JerseyNumberDataset(\n",
    "        root_dir=test_dir,\n",
    "        json_path=os.path.join(test_dir, 'test_gt.json'),\n",
    "        transform=val_transform,\n",
    "        number_mapping=number_mapping,\n",
    "        is_train=False\n",
    "    )\n",
    "\n",
    "    return train_dataset, val_dataset, len(number_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPWHHkbbcaGX"
   },
   "outputs": [],
   "source": [
    "class JerseyNumberNet(nn.Module):\n",
    "    def __init__(self, num_classes=101):  # 100 numbers + 1 for no number\n",
    "        super(JerseyNumberNet, self).__init__()\n",
    "\n",
    "        # Use ResNet18 as backbone\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "\n",
    "        # Modify the first conv layer to handle potential different input size\n",
    "        self.backbone.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Replace the final FC layer\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "        # Add attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv2d(512, 1, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        features = self.backbone.layer4(x)\n",
    "\n",
    "        # Apply attention\n",
    "        att = self.attention(features)\n",
    "        features = features * att\n",
    "\n",
    "        # Global average pooling and classification\n",
    "        x = F.adaptive_avg_pool2d(features, (1, 1))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.backbone.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSIPMRYRcd2I"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=1, device='cuda'):\n",
    "    \"\"\"\n",
    "    Training function with validation\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            print('training right now')\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            print(f'Training Loss: {running_loss/len(train_loader):.4f}')\n",
    "            print(f'Training Accuracy: {100. * correct / total:.2f}%')\n",
    "\n",
    "        train_acc = 100. * correct / total\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        val_acc = 100. * val_correct / val_total\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'Training Loss: {running_loss/len(train_loader):.4f}')\n",
    "        print(f'Training Accuracy: {train_acc:.2f}%')\n",
    "        print(f'Validation Accuracy: {val_acc:.2f}%')\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_jersey_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjaeeX6Ice2e"
   },
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Create datasets with consistent class mapping\n",
    "        train_dataset, val_dataset, num_classes = create_datasets(\n",
    "            train_dir='/content/train',\n",
    "            test_dir='/content/test'\n",
    "        )\n",
    "\n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "        # Initialize model with correct number of classes\n",
    "        print(f\"\\nInitializing model with {num_classes} classes\")\n",
    "        model = JerseyNumberNet(num_classes=num_classes)\n",
    "\n",
    "        # Calculate class weights for weighted loss\n",
    "        class_counts = torch.zeros(num_classes)\n",
    "        for sample in train_dataset.samples:\n",
    "            class_idx = train_dataset.number_to_idx[sample['number']]\n",
    "            class_counts[class_idx] += 1\n",
    "\n",
    "        class_weights = 1.0 / (class_counts + 1e-6)\n",
    "        class_weights = class_weights / class_weights.sum()\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights.cuda())\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Train the model\n",
    "        train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during initialization: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gt5HJP5Icp5r",
    "outputId": "e5b79f33-afd4-484d-8d01-14a43f477f67"
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "KQixkmEvniDM",
    "outputId": "9611fb99-4a1c-4307-a13e-68b938b92aa0"
   },
   "outputs": [],
   "source": [
    "\n",
    "## Test the model on any random image\n",
    "\n",
    "# Load the model\n",
    "\n",
    "model = JerseyNumberNet(num_classes=55)\n",
    "model.load_state_dict(torch.load('/home/sahilc/Sports-Analysis/Jersey Number Recognition/best_jersey_model (1).pth'))\n",
    "model.eval()\n",
    "\n",
    "image_path = '/home/sahilc/Sports-Analysis/Jersey Number Recognition/train/images/1/1_15.jpg'\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "image = transform(image)\n",
    "image = image.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "print(f\"Predicted jersey number: {predicted.item()}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "Nqw1wmDrpDpL",
    "outputId": "29f07597-5e46-4c18-b28b-599531bef651"
   },
   "outputs": [],
   "source": [
    "## view the image to confirm\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Open the image\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Turn off axis labels\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
