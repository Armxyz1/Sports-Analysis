{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1L1shvC7ZyW1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import json\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CymhUYhwZ3MI",
        "outputId": "f89683d2-90a5-46ba-b264-b166d333717b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SoccerNet in /home/sahilc/miniconda3/lib/python3.12/site-packages (0.1.61)\n",
            "Requirement already satisfied: tqdm in /home/sahilc/miniconda3/lib/python3.12/site-packages (from SoccerNet) (4.66.4)\n",
            "Requirement already satisfied: scikit-video in /home/sahilc/miniconda3/lib/python3.12/site-packages (from SoccerNet) (1.1.11)\n",
            "Requirement already satisfied: matplotlib in /home/sahilc/miniconda3/lib/python3.12/site-packages (from SoccerNet) (3.9.1)\n",
            "Requirement already satisfied: google-measurement-protocol in /home/sahilc/miniconda3/lib/python3.12/site-packages (from SoccerNet) (1.1.0)\n",
            "Requirement already satisfied: pycocoevalcap in /home/sahilc/miniconda3/lib/python3.12/site-packages (from SoccerNet) (1.2)\n",
            "Requirement already satisfied: huggingface-hub[cli] in /home/sahilc/miniconda3/lib/python3.12/site-packages (from SoccerNet) (0.23.4)\n",
            "Requirement already satisfied: requests<3.0a0,>=2.0 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from google-measurement-protocol->SoccerNet) (2.32.3)\n",
            "Requirement already satisfied: prices>=1.0.0 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from google-measurement-protocol->SoccerNet) (1.1.1)\n",
            "Requirement already satisfied: filelock in /home/sahilc/miniconda3/lib/python3.12/site-packages (from huggingface-hub[cli]->SoccerNet) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from huggingface-hub[cli]->SoccerNet) (2024.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from huggingface-hub[cli]->SoccerNet) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from huggingface-hub[cli]->SoccerNet) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from huggingface-hub[cli]->SoccerNet) (4.12.2)\n",
            "Requirement already satisfied: InquirerPy==0.3.4 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from huggingface-hub[cli]->SoccerNet) (0.3.4)\n",
            "Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from InquirerPy==0.3.4->huggingface-hub[cli]->SoccerNet) (0.3.4)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from InquirerPy==0.3.4->huggingface-hub[cli]->SoccerNet) (3.0.47)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from matplotlib->SoccerNet) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from matplotlib->SoccerNet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from matplotlib->SoccerNet) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from matplotlib->SoccerNet) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from matplotlib->SoccerNet) (1.26.4)\n",
            "Requirement already satisfied: pillow>=8 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from matplotlib->SoccerNet) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from matplotlib->SoccerNet) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from matplotlib->SoccerNet) (2.9.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from pycocoevalcap->SoccerNet) (2.0.8)\n",
            "Requirement already satisfied: scipy in /home/sahilc/miniconda3/lib/python3.12/site-packages (from scikit-video->SoccerNet) (1.14.0)\n",
            "Requirement already satisfied: babel>=2.5.0 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from prices>=1.0.0->google-measurement-protocol->SoccerNet) (2.14.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->SoccerNet) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/sahilc/miniconda3/lib/python3.12/site-packages (from requests<3.0a0,>=2.0->google-measurement-protocol->SoccerNet) (2024.7.4)\n",
            "Requirement already satisfied: wcwidth in /home/sahilc/miniconda3/lib/python3.12/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface-hub[cli]->SoccerNet) (0.2.13)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install SoccerNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6pZGicdZ4-b",
        "outputId": "134f8b5b-6651-460e-f2f0-c9638b241601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZHMHE8paMkm",
        "outputId": "0381390c-370d-4b91-d312-9af412d18c7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "path/to/SoccerNet/jersey-2023/train.zip already exists\n",
            "path/to/SoccerNet/jersey-2023/test.zip already exists\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sahilc/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from SoccerNet.Downloader import SoccerNetDownloader as SNdl\n",
        "mySNdl = SNdl(LocalDirectory=\"path/to/SoccerNet\")\n",
        "mySNdl.downloadDataTask(task=\"jersey-2023\", split=[\"train\",\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4f-vd5paQae",
        "outputId": "1c5bc1f0-066c-41ca-b011-67add3bf74c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/path/to/SoccerNet/jersey-2023/test.zip\n",
            "replace /content/test/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: Archive:  /content/path/to/SoccerNet/jersey-2023/train.zip\n",
            "replace /content/train/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# Extract the zip file to drive\n",
        "!unzip /content/path/to/SoccerNet/jersey-2023/test.zip -d /content\n",
        "!unzip /content/path/to/SoccerNet/jersey-2023/train.zip -d /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVe6jYVsaUPE",
        "outputId": "25c832af-c644-47fa-87cf-20929e14f296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 44, 50, 55, 56, 62, 75, 93, -1]\n",
            "45\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 40, 43, 44, 45, 50, 53, 55, 56, 59, 60, 62, 69, 75, 76, 78, 93, 99, -1]\n",
            "55\n"
          ]
        }
      ],
      "source": [
        "## Go through json file and figure out the unique classes\n",
        "\n",
        "classes = []\n",
        "with open(\"/home/sahilc/Sports-Analysis/Jersey Number Recognition/train/train_gt.json\") as f:\n",
        "    data = json.load(f)\n",
        "    for img_path, number in data.items():\n",
        "        classes.append(number)\n",
        "classes = list(set(classes))\n",
        "num_classes = len(classes)\n",
        "print(classes)\n",
        "print(num_classes)\n",
        "\n",
        "## Test it for test.json\n",
        "with open(\"/home/sahilc/Sports-Analysis/Jersey Number Recognition/test/test_gt.json\") as f:\n",
        "    data = json.load(f)\n",
        "    for img_path, number in data.items():\n",
        "        classes.append(number)\n",
        "classes = list(set(classes))\n",
        "num_classes = len(classes)\n",
        "print(classes)\n",
        "print(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_bUycoIEcZCv"
      },
      "outputs": [],
      "source": [
        "class JerseyNumberDataset(Dataset):\n",
        "    def __init__(self, root_dir, json_path, transform=None, is_train=True, number_mapping=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (str): Directory containing the images folder\n",
        "            json_path (str): Path to the ground truth JSON file\n",
        "            transform: Optional transform to be applied on images\n",
        "            is_train (bool): If True, performs data augmentation\n",
        "            number_mapping (dict): Optional mapping from jersey numbers to class indices\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.is_train = is_train\n",
        "\n",
        "        # Load annotations\n",
        "        print(f\"Loading annotations from {json_path}\")\n",
        "        with open(json_path, 'r') as f:\n",
        "            self.annotations = json.load(f)\n",
        "\n",
        "        # Create samples list\n",
        "        self.samples = []\n",
        "        images_dir = os.path.join(root_dir, \"images\")\n",
        "\n",
        "        print(f\"Looking for images in {images_dir}\")\n",
        "        if not os.path.exists(images_dir):\n",
        "            raise ValueError(f\"Images directory not found at {images_dir}\")\n",
        "\n",
        "        # Get all valid image paths and their labels\n",
        "        all_numbers = set()\n",
        "\n",
        "        # Handle nested directory structure\n",
        "        for img_path, number in self.annotations.items():\n",
        "            player_dir = os.path.join(images_dir, img_path)\n",
        "            if os.path.isdir(player_dir):\n",
        "                # If it's a directory, get all images inside it\n",
        "                for img_file in os.listdir(player_dir):\n",
        "                    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                        full_path = os.path.join(player_dir, img_file)\n",
        "                        all_numbers.add(number)\n",
        "                        self.samples.append({\n",
        "                            'img_path': full_path,\n",
        "                            'number': number\n",
        "                        })\n",
        "            elif os.path.isfile(player_dir) and player_dir.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                # If it's directly an image file\n",
        "                all_numbers.add(number)\n",
        "                self.samples.append({\n",
        "                    'img_path': player_dir,\n",
        "                    'number': number\n",
        "                })\n",
        "\n",
        "        # Create number to index mapping if not provided\n",
        "        if number_mapping is None:\n",
        "            sorted_numbers = sorted(list(all_numbers))\n",
        "            self.number_to_idx = {num: idx for idx, num in enumerate(sorted_numbers)}\n",
        "        else:\n",
        "            self.number_to_idx = number_mapping\n",
        "\n",
        "        print(f\"Found {len(self.samples)} valid images\")\n",
        "        if len(self.samples) == 0:\n",
        "            raise ValueError(f\"No valid samples found in {images_dir}\")\n",
        "\n",
        "        # Print class distribution\n",
        "        numbers = [sample['number'] for sample in self.samples]\n",
        "        class_dist = {}\n",
        "        for num in numbers:\n",
        "            class_dist[num] = class_dist.get(num, 0) + 1\n",
        "        print(\"\\nClass distribution:\")\n",
        "        for num, count in sorted(class_dist.items()):\n",
        "            print(f\"Number {num}: {count} samples ({count/len(numbers)*100:.2f}%)\")\n",
        "\n",
        "        print(\"\\nClass mapping:\")\n",
        "        for num, idx in sorted(self.number_to_idx.items()):\n",
        "            print(f\"Jersey number {num} -> Class index {idx}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "\n",
        "        try:\n",
        "            image = Image.open(sample['img_path']).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {sample['img_path']}: {str(e)}\")\n",
        "            return self.__getitem__((idx + 1) % len(self))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        target = self.number_to_idx[sample['number']]\n",
        "        return image, target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-XDe6_egd9O7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_datasets(train_dir, test_dir):\n",
        "    \"\"\"Create train and validation datasets with consistent class mapping\"\"\"\n",
        "    # First, gather all possible numbers from both train and test sets\n",
        "    all_numbers = set()\n",
        "\n",
        "    # From training set\n",
        "    with open(os.path.join(train_dir, 'train_gt.json'), 'r') as f:\n",
        "        train_annotations = json.load(f)\n",
        "        all_numbers.update(train_annotations.values())\n",
        "\n",
        "    # From test set\n",
        "    with open(os.path.join(test_dir, 'test_gt.json'), 'r') as f:\n",
        "        test_annotations = json.load(f)\n",
        "        all_numbers.update(test_annotations.values())\n",
        "\n",
        "    # Create mapping\n",
        "    sorted_numbers = sorted(list(all_numbers))\n",
        "    number_mapping = {num: idx for idx, num in enumerate(sorted_numbers)}\n",
        "\n",
        "    print(f\"\\nTotal unique jersey numbers found: {len(number_mapping)}\")\n",
        "\n",
        "    # Data transforms\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(15),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "        transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_transform = transforms.Compose([\n",
        "        transforms.Resize((128, 128)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Create datasets with shared mapping\n",
        "    train_dataset = JerseyNumberDataset(\n",
        "        root_dir=train_dir,\n",
        "        json_path=os.path.join(train_dir, 'train_gt.json'),\n",
        "        transform=train_transform,\n",
        "        number_mapping=number_mapping\n",
        "    )\n",
        "\n",
        "    val_dataset = JerseyNumberDataset(\n",
        "        root_dir=test_dir,\n",
        "        json_path=os.path.join(test_dir, 'test_gt.json'),\n",
        "        transform=val_transform,\n",
        "        number_mapping=number_mapping,\n",
        "        is_train=False\n",
        "    )\n",
        "\n",
        "    return train_dataset, val_dataset, len(number_mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pPWHHkbbcaGX"
      },
      "outputs": [],
      "source": [
        "class JerseyNumberNet(nn.Module):\n",
        "    def __init__(self, num_classes=101):  # 100 numbers + 1 for no number\n",
        "        super(JerseyNumberNet, self).__init__()\n",
        "\n",
        "        # Use ResNet18 as backbone\n",
        "        self.backbone = models.resnet18(pretrained=True)\n",
        "\n",
        "        # Modify the first conv layer to handle potential different input size\n",
        "        self.backbone.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "        # Replace the final FC layer\n",
        "        num_features = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Sequential(\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "        # Add attention mechanism\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Conv2d(512, 1, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Extract features\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "\n",
        "        x = self.backbone.layer1(x)\n",
        "        x = self.backbone.layer2(x)\n",
        "        x = self.backbone.layer3(x)\n",
        "        features = self.backbone.layer4(x)\n",
        "\n",
        "        # Apply attention\n",
        "        att = self.attention(features)\n",
        "        features = features * att\n",
        "\n",
        "        # Global average pooling and classification\n",
        "        x = F.adaptive_avg_pool2d(features, (1, 1))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.backbone.fc(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "oSIPMRYRcd2I"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=1, device='cuda'):\n",
        "    \"\"\"\n",
        "    Training function with validation\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            print('training right now')\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            print(f'Training Loss: {running_loss/len(train_loader):.4f}')\n",
        "            print(f'Training Accuracy: {100. * correct / total:.2f}%')\n",
        "\n",
        "        train_acc = 100. * correct / total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = outputs.max(1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        val_acc = 100. * val_correct / val_total\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "        print(f'Training Loss: {running_loss/len(train_loader):.4f}')\n",
        "        print(f'Training Accuracy: {train_acc:.2f}%')\n",
        "        print(f'Validation Accuracy: {val_acc:.2f}%')\n",
        "\n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), 'best_jersey_model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NjaeeX6Ice2e"
      },
      "outputs": [],
      "source": [
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Create datasets with consistent class mapping\n",
        "        train_dataset, val_dataset, num_classes = create_datasets(\n",
        "            train_dir='/content/train',\n",
        "            test_dir='/content/test'\n",
        "        )\n",
        "\n",
        "        # Create data loaders\n",
        "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "        # Initialize model with correct number of classes\n",
        "        print(f\"\\nInitializing model with {num_classes} classes\")\n",
        "        model = JerseyNumberNet(num_classes=num_classes)\n",
        "\n",
        "        # Calculate class weights for weighted loss\n",
        "        class_counts = torch.zeros(num_classes)\n",
        "        for sample in train_dataset.samples:\n",
        "            class_idx = train_dataset.number_to_idx[sample['number']]\n",
        "            class_counts[class_idx] += 1\n",
        "\n",
        "        class_weights = 1.0 / (class_counts + 1e-6)\n",
        "        class_weights = class_weights / class_weights.sum()\n",
        "        criterion = nn.CrossEntropyLoss(weight=class_weights.cuda())\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "        # Train the model\n",
        "        train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during initialization: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt5HJP5Icp5r",
        "outputId": "e5b79f33-afd4-484d-8d01-14a43f477f67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total unique jersey numbers found: 55\n",
            "Loading annotations from /content/train/train_gt.json\n",
            "Looking for images in /content/train/images\n",
            "Found 733001 valid images\n",
            "\n",
            "Class distribution:\n",
            "Number -1: 172257 samples (23.50%)\n",
            "Number 1: 41826 samples (5.71%)\n",
            "Number 2: 4917 samples (0.67%)\n",
            "Number 3: 20622 samples (2.81%)\n",
            "Number 4: 28153 samples (3.84%)\n",
            "Number 5: 13875 samples (1.89%)\n",
            "Number 6: 22591 samples (3.08%)\n",
            "Number 7: 10402 samples (1.42%)\n",
            "Number 8: 34325 samples (4.68%)\n",
            "Number 9: 37139 samples (5.07%)\n",
            "Number 10: 47700 samples (6.51%)\n",
            "Number 11: 10380 samples (1.42%)\n",
            "Number 13: 1038 samples (0.14%)\n",
            "Number 14: 36406 samples (4.97%)\n",
            "Number 15: 7502 samples (1.02%)\n",
            "Number 16: 7659 samples (1.04%)\n",
            "Number 17: 7409 samples (1.01%)\n",
            "Number 18: 1667 samples (0.23%)\n",
            "Number 19: 2482 samples (0.34%)\n",
            "Number 20: 14485 samples (1.98%)\n",
            "Number 21: 3126 samples (0.43%)\n",
            "Number 22: 7854 samples (1.07%)\n",
            "Number 23: 7260 samples (0.99%)\n",
            "Number 24: 24877 samples (3.39%)\n",
            "Number 25: 17485 samples (2.39%)\n",
            "Number 26: 9813 samples (1.34%)\n",
            "Number 27: 12802 samples (1.75%)\n",
            "Number 28: 12110 samples (1.65%)\n",
            "Number 29: 11815 samples (1.61%)\n",
            "Number 30: 15069 samples (2.06%)\n",
            "Number 31: 8396 samples (1.15%)\n",
            "Number 32: 826 samples (0.11%)\n",
            "Number 33: 16886 samples (2.30%)\n",
            "Number 34: 8583 samples (1.17%)\n",
            "Number 35: 1218 samples (0.17%)\n",
            "Number 36: 16815 samples (2.29%)\n",
            "Number 38: 750 samples (0.10%)\n",
            "Number 40: 3715 samples (0.51%)\n",
            "Number 44: 8167 samples (1.11%)\n",
            "Number 50: 7446 samples (1.02%)\n",
            "Number 55: 7374 samples (1.01%)\n",
            "Number 56: 311 samples (0.04%)\n",
            "Number 62: 6236 samples (0.85%)\n",
            "Number 75: 482 samples (0.07%)\n",
            "Number 93: 750 samples (0.10%)\n",
            "\n",
            "Class mapping:\n",
            "Jersey number -1 -> Class index 0\n",
            "Jersey number 1 -> Class index 1\n",
            "Jersey number 2 -> Class index 2\n",
            "Jersey number 3 -> Class index 3\n",
            "Jersey number 4 -> Class index 4\n",
            "Jersey number 5 -> Class index 5\n",
            "Jersey number 6 -> Class index 6\n",
            "Jersey number 7 -> Class index 7\n",
            "Jersey number 8 -> Class index 8\n",
            "Jersey number 9 -> Class index 9\n",
            "Jersey number 10 -> Class index 10\n",
            "Jersey number 11 -> Class index 11\n",
            "Jersey number 12 -> Class index 12\n",
            "Jersey number 13 -> Class index 13\n",
            "Jersey number 14 -> Class index 14\n",
            "Jersey number 15 -> Class index 15\n",
            "Jersey number 16 -> Class index 16\n",
            "Jersey number 17 -> Class index 17\n",
            "Jersey number 18 -> Class index 18\n",
            "Jersey number 19 -> Class index 19\n",
            "Jersey number 20 -> Class index 20\n",
            "Jersey number 21 -> Class index 21\n",
            "Jersey number 22 -> Class index 22\n",
            "Jersey number 23 -> Class index 23\n",
            "Jersey number 24 -> Class index 24\n",
            "Jersey number 25 -> Class index 25\n",
            "Jersey number 26 -> Class index 26\n",
            "Jersey number 27 -> Class index 27\n",
            "Jersey number 28 -> Class index 28\n",
            "Jersey number 29 -> Class index 29\n",
            "Jersey number 30 -> Class index 30\n",
            "Jersey number 31 -> Class index 31\n",
            "Jersey number 32 -> Class index 32\n",
            "Jersey number 33 -> Class index 33\n",
            "Jersey number 34 -> Class index 34\n",
            "Jersey number 35 -> Class index 35\n",
            "Jersey number 36 -> Class index 36\n",
            "Jersey number 38 -> Class index 37\n",
            "Jersey number 40 -> Class index 38\n",
            "Jersey number 43 -> Class index 39\n",
            "Jersey number 44 -> Class index 40\n",
            "Jersey number 45 -> Class index 41\n",
            "Jersey number 50 -> Class index 42\n",
            "Jersey number 53 -> Class index 43\n",
            "Jersey number 55 -> Class index 44\n",
            "Jersey number 56 -> Class index 45\n",
            "Jersey number 59 -> Class index 46\n",
            "Jersey number 60 -> Class index 47\n",
            "Jersey number 62 -> Class index 48\n",
            "Jersey number 69 -> Class index 49\n",
            "Jersey number 75 -> Class index 50\n",
            "Jersey number 76 -> Class index 51\n",
            "Jersey number 78 -> Class index 52\n",
            "Jersey number 93 -> Class index 53\n",
            "Jersey number 99 -> Class index 54\n",
            "Loading annotations from /content/test/test_gt.json\n",
            "Looking for images in /content/test/images\n",
            "Found 564547 valid images\n",
            "\n",
            "Class distribution:\n",
            "Number -1: 130090 samples (23.04%)\n",
            "Number 1: 35153 samples (6.23%)\n",
            "Number 2: 3694 samples (0.65%)\n",
            "Number 3: 7364 samples (1.30%)\n",
            "Number 4: 19926 samples (3.53%)\n",
            "Number 5: 11187 samples (1.98%)\n",
            "Number 6: 472 samples (0.08%)\n",
            "Number 7: 16192 samples (2.87%)\n",
            "Number 8: 14825 samples (2.63%)\n",
            "Number 9: 22537 samples (3.99%)\n",
            "Number 10: 30865 samples (5.47%)\n",
            "Number 11: 8894 samples (1.58%)\n",
            "Number 12: 201 samples (0.04%)\n",
            "Number 14: 40884 samples (7.24%)\n",
            "Number 15: 12131 samples (2.15%)\n",
            "Number 16: 14247 samples (2.52%)\n",
            "Number 17: 6485 samples (1.15%)\n",
            "Number 18: 264 samples (0.05%)\n",
            "Number 20: 11274 samples (2.00%)\n",
            "Number 21: 648 samples (0.11%)\n",
            "Number 22: 6536 samples (1.16%)\n",
            "Number 23: 5764 samples (1.02%)\n",
            "Number 24: 9364 samples (1.66%)\n",
            "Number 25: 14106 samples (2.50%)\n",
            "Number 26: 8038 samples (1.42%)\n",
            "Number 27: 9511 samples (1.68%)\n",
            "Number 29: 750 samples (0.13%)\n",
            "Number 30: 4850 samples (0.86%)\n",
            "Number 31: 12367 samples (2.19%)\n",
            "Number 32: 2324 samples (0.41%)\n",
            "Number 33: 23766 samples (4.21%)\n",
            "Number 34: 10538 samples (1.87%)\n",
            "Number 36: 21677 samples (3.84%)\n",
            "Number 38: 401 samples (0.07%)\n",
            "Number 43: 1009 samples (0.18%)\n",
            "Number 44: 9300 samples (1.65%)\n",
            "Number 45: 522 samples (0.09%)\n",
            "Number 50: 9772 samples (1.73%)\n",
            "Number 53: 199 samples (0.04%)\n",
            "Number 55: 5418 samples (0.96%)\n",
            "Number 56: 928 samples (0.16%)\n",
            "Number 59: 2388 samples (0.42%)\n",
            "Number 60: 348 samples (0.06%)\n",
            "Number 62: 7528 samples (1.33%)\n",
            "Number 69: 299 samples (0.05%)\n",
            "Number 76: 532 samples (0.09%)\n",
            "Number 78: 506 samples (0.09%)\n",
            "Number 93: 8211 samples (1.45%)\n",
            "Number 99: 262 samples (0.05%)\n",
            "\n",
            "Class mapping:\n",
            "Jersey number -1 -> Class index 0\n",
            "Jersey number 1 -> Class index 1\n",
            "Jersey number 2 -> Class index 2\n",
            "Jersey number 3 -> Class index 3\n",
            "Jersey number 4 -> Class index 4\n",
            "Jersey number 5 -> Class index 5\n",
            "Jersey number 6 -> Class index 6\n",
            "Jersey number 7 -> Class index 7\n",
            "Jersey number 8 -> Class index 8\n",
            "Jersey number 9 -> Class index 9\n",
            "Jersey number 10 -> Class index 10\n",
            "Jersey number 11 -> Class index 11\n",
            "Jersey number 12 -> Class index 12\n",
            "Jersey number 13 -> Class index 13\n",
            "Jersey number 14 -> Class index 14\n",
            "Jersey number 15 -> Class index 15\n",
            "Jersey number 16 -> Class index 16\n",
            "Jersey number 17 -> Class index 17\n",
            "Jersey number 18 -> Class index 18\n",
            "Jersey number 19 -> Class index 19\n",
            "Jersey number 20 -> Class index 20\n",
            "Jersey number 21 -> Class index 21\n",
            "Jersey number 22 -> Class index 22\n",
            "Jersey number 23 -> Class index 23\n",
            "Jersey number 24 -> Class index 24\n",
            "Jersey number 25 -> Class index 25\n",
            "Jersey number 26 -> Class index 26\n",
            "Jersey number 27 -> Class index 27\n",
            "Jersey number 28 -> Class index 28\n",
            "Jersey number 29 -> Class index 29\n",
            "Jersey number 30 -> Class index 30\n",
            "Jersey number 31 -> Class index 31\n",
            "Jersey number 32 -> Class index 32\n",
            "Jersey number 33 -> Class index 33\n",
            "Jersey number 34 -> Class index 34\n",
            "Jersey number 35 -> Class index 35\n",
            "Jersey number 36 -> Class index 36\n",
            "Jersey number 38 -> Class index 37\n",
            "Jersey number 40 -> Class index 38\n",
            "Jersey number 43 -> Class index 39\n",
            "Jersey number 44 -> Class index 40\n",
            "Jersey number 45 -> Class index 41\n",
            "Jersey number 50 -> Class index 42\n",
            "Jersey number 53 -> Class index 43\n",
            "Jersey number 55 -> Class index 44\n",
            "Jersey number 56 -> Class index 45\n",
            "Jersey number 59 -> Class index 46\n",
            "Jersey number 60 -> Class index 47\n",
            "Jersey number 62 -> Class index 48\n",
            "Jersey number 69 -> Class index 49\n",
            "Jersey number 75 -> Class index 50\n",
            "Jersey number 76 -> Class index 51\n",
            "Jersey number 78 -> Class index 52\n",
            "Jersey number 93 -> Class index 53\n",
            "Jersey number 99 -> Class index 54\n",
            "\n",
            "Initializing model with 55 classes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1233\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1233\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1233\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1234\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1234\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1234\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1234\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1234\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1235\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1235\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1235\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1235\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1235\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1236\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1236\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1236\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1236\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1236\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1236\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1237\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1237\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1237\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1237\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1237\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1238\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1238\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1238\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1238\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1239\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1239\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1239\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1239\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1240\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1240\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1240\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1240\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1241\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1241\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1241\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1241\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1241\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1242\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1242\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1242\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1243\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1243\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1243\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1243\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1243\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1244\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1244\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1244\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1245\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1245\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1245\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1245\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1246\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1246\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1246\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1246\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1246\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1247\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1247\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1247\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1247\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1247\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1247\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1248\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1248\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1248\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1248\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1249\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1249\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1249\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1249\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1250\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1250\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1250\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1250\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1251\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1251\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1251\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1251\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1252\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1252\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1252\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1252\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1252\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1253\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1253\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1253\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1254\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1254\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1254\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1254\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1254\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1255\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1255\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1255\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1255\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1256\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1256\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1256\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1256\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1256\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1257\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1257\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1258\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1258\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1258\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1259\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1259\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1259\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1259\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1260\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1260\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1260\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1260\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1261\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1261\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1261\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1261\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1262\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1262\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1262\n",
            "Training Accuracy: 69.68%\n",
            "training right now\n",
            "Training Loss: 0.1263\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1263\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1263\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1263\n",
            "Training Accuracy: 69.68%\n",
            "training right now\n",
            "Training Loss: 0.1263\n",
            "Training Accuracy: 69.68%\n",
            "training right now\n",
            "Training Loss: 0.1264\n",
            "Training Accuracy: 69.68%\n",
            "training right now\n",
            "Training Loss: 0.1264\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1264\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1264\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1265\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1265\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1265\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1265\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1265\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1266\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1266\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1266\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1267\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1267\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1267\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1267\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1267\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1268\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1268\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1268\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1268\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1269\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1269\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1269\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1270\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1270\n",
            "Training Accuracy: 69.68%\n",
            "training right now\n",
            "Training Loss: 0.1270\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1270\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1270\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1270\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1271\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1271\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1271\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1271\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1272\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1272\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1272\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1272\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1272\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1273\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1273\n",
            "Training Accuracy: 69.69%\n",
            "training right now\n",
            "Training Loss: 0.1273\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1273\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1273\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1274\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1274\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1274\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1274\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1275\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1275\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1275\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1275\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1276\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1276\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1276\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1277\n",
            "Training Accuracy: 69.70%\n",
            "training right now\n",
            "Training Loss: 0.1277\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1277\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1277\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1278\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1278\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1278\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1278\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1278\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1279\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1279\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1279\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1279\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1280\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1280\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1280\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1280\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1281\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1281\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1281\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1281\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1281\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1282\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1282\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1282\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1282\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1283\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1283\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1283\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1283\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1283\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1284\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1284\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1284\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1284\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1284\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1285\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1285\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1285\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1285\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1286\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1286\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1286\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1286\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1287\n",
            "Training Accuracy: 69.71%\n",
            "training right now\n",
            "Training Loss: 0.1287\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1287\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1287\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1287\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1287\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1287\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1288\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1288\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1288\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1289\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1289\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1289\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1289\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1290\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1290\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1290\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1290\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1290\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1291\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1291\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1291\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1291\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1292\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1292\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1292\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1293\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1293\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1293\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1293\n",
            "Training Accuracy: 69.72%\n",
            "training right now\n",
            "Training Loss: 0.1293\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1293\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1294\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1294\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1294\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1294\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1294\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1295\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1295\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1295\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1296\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1296\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1296\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1296\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1297\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1297\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1297\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1297\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1298\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1298\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1298\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1298\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1299\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1299\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1299\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1299\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1299\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1300\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1300\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1300\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1300\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1300\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1301\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1301\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1301\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1302\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1302\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1302\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1302\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1302\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1303\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1303\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1303\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1303\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1303\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1304\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1304\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1304\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1304\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1305\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1305\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1305\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1306\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1306\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1306\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1306\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1306\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1307\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1307\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1307\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1307\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1308\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1308\n",
            "Training Accuracy: 69.73%\n",
            "training right now\n",
            "Training Loss: 0.1308\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1308\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1309\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1309\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1309\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1309\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1309\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1309\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1310\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1310\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1310\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1310\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1310\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1311\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1311\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1311\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1311\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1311\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1312\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1312\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1312\n",
            "Training Accuracy: 69.74%\n",
            "training right now\n",
            "Training Loss: 0.1312\n",
            "Training Accuracy: 69.75%\n",
            "training right now\n",
            "Training Loss: 0.1312\n",
            "Training Accuracy: 69.75%\n",
            "training right now\n",
            "Training Loss: 0.1313\n",
            "Training Accuracy: 69.75%\n",
            "training right now\n",
            "Training Loss: 0.1313\n",
            "Training Accuracy: 69.75%\n",
            "training right now\n",
            "Training Loss: 0.1313\n",
            "Training Accuracy: 69.75%\n",
            "training right now\n",
            "Training Loss: 0.1313\n",
            "Training Accuracy: 69.75%\n",
            "training right now\n",
            "Training Loss: 0.1313\n",
            "Training Accuracy: 69.75%\n",
            "training right now\n",
            "Training Loss: 0.1313\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1314\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1314\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1314\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1314\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1314\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1315\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1315\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1315\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1315\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1315\n",
            "Training Accuracy: 69.75%\n",
            "training right now\n",
            "Training Loss: 0.1316\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1316\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1316\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1316\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1316\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1317\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1317\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1317\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1317\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1317\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1317\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1317\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1318\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1318\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1319\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1319\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1319\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1319\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1319\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1320\n",
            "Training Accuracy: 69.76%\n",
            "training right now\n",
            "Training Loss: 0.1320\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1320\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1321\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1321\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1321\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1321\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1321\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1322\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1322\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1322\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1322\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1322\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1323\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1323\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1323\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1323\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1323\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1324\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1324\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1324\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1324\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1324\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1325\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1325\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1325\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1326\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1327\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1327\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1327\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1327\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1328\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1328\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1328\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1329\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1329\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1329\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1330\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1330\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1330\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1331\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1331\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1332\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1332\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1332\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1332\n",
            "Training Accuracy: 69.77%\n",
            "training right now\n",
            "Training Loss: 0.1332\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1332\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1333\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1333\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1333\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1333\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1333\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1334\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1334\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1334\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1334\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1335\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1335\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1335\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1335\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1335\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1336\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1336\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1336\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1336\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1336\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1336\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1337\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1337\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1337\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1338\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1338\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1338\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1338\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1338\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1339\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1339\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1339\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1339\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1339\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1340\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1340\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1341\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1341\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1341\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1341\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1341\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1342\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1342\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1342\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1343\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1343\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1343\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1343\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1343\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1343\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1343\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1343\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1344\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1344\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1344\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1344\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1345\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1345\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1345\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1345\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1346\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1346\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1346\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1346\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1346\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1347\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1347\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1347\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1348\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1349\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1349\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1349\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1349\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1349\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1349\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1349\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1349\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1349\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1350\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1350\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1351\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1351\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1351\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1351\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1352\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1352\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1352\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1352\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1353\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1353\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1353\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1354\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1354\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1354\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1355\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1355\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1355\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1356\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1356\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1356\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1356\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1356\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1357\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1357\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1357\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1358\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1358\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1358\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1359\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1359\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1359\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1359\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1359\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1360\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1360\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1360\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1360\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1360\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1361\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1361\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1361\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1361\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1361\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1363\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1363\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1363\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1363\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1364\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1364\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1364\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1364\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1364\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1365\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1365\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1365\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1365\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1366\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1366\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1366\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1366\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1367\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1367\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1367\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1368\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1368\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1368\n",
            "Training Accuracy: 69.78%\n",
            "training right now\n",
            "Training Loss: 0.1368\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1368\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1368\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1369\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1369\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1369\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1369\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1369\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1370\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1370\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1370\n",
            "Training Accuracy: 69.79%\n",
            "training right now\n",
            "Training Loss: 0.1370\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1370\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1370\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1371\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1371\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1371\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1371\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1371\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1372\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1372\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1372\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1372\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1373\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1373\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1373\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1373\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1373\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1373\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1373\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1374\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1374\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1375\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1375\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1375\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1375\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1376\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1376\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1376\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1376\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1376\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1377\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1377\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1377\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1377\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1378\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1378\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1378\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1378\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1378\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1379\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1379\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1379\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1379\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1379\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1380\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1380\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1380\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1380\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1380\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1381\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1381\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1382\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1382\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1382\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1382\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1382\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1382\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1382\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1383\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1383\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1383\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1383\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1383\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1384\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1384\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1384\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1384\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1384\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1385\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1385\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1385\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1385\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1386\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1386\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1386\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1386\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1387\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1388\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1388\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1388\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1389\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1389\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1389\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1389\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1389\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1390\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1390\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1390\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1390\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1391\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1391\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1391\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1392\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1392\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1392\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1392\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1392\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1393\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1393\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1393\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1393\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1394\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1394\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1394\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1394\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1395\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1395\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1395\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1395\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1396\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1396\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1396\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1397\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1397\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1397\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1398\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1398\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1398\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1398\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1399\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1399\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1399\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1399\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1399\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1400\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1400\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1400\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1400\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1400\n",
            "Training Accuracy: 69.80%\n",
            "training right now\n",
            "Training Loss: 0.1401\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1401\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1401\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1401\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1402\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1402\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1402\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1402\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1402\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1403\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1403\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1403\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1403\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1403\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1403\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1404\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1404\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1404\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1405\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1405\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1405\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1405\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1406\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1406\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1406\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1406\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1406\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1407\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1407\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1407\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1408\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1408\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1408\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1408\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1408\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1409\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1409\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1409\n",
            "Training Accuracy: 69.81%\n",
            "training right now\n",
            "Training Loss: 0.1409\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1409\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1410\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1410\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1410\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1410\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1411\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1411\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1411\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1411\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1412\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1412\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1412\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1412\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1412\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1413\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1413\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1413\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1413\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1414\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1414\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1414\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1414\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1414\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1415\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1415\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1415\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1415\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1415\n",
            "Training Accuracy: 69.82%\n",
            "training right now\n",
            "Training Loss: 0.1415\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1416\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1416\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1416\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1416\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1417\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1417\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1417\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1417\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1418\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1418\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1418\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1418\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1419\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1419\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1419\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1419\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1419\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1420\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1420\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1420\n",
            "Training Accuracy: 69.83%\n",
            "training right now\n",
            "Training Loss: 0.1421\n",
            "Training Accuracy: 69.84%\n",
            "training right now\n",
            "Training Loss: 0.1421\n",
            "Training Accuracy: 69.84%\n",
            "training right now\n",
            "Training Loss: 0.1421\n",
            "Training Accuracy: 69.84%\n",
            "training right now\n",
            "Training Loss: 0.1421\n",
            "Training Accuracy: 69.84%\n",
            "training right now\n",
            "Training Loss: 0.1421\n",
            "Training Accuracy: 69.84%\n",
            "training right now\n",
            "Training Loss: 0.1421\n",
            "Training Accuracy: 69.84%\n",
            "training right now\n",
            "Training Loss: 0.1422\n",
            "Training Accuracy: 69.84%\n",
            "training right now\n",
            "Training Loss: 0.1422\n",
            "Training Accuracy: 69.84%\n",
            "training right now\n",
            "Training Loss: 0.1422\n",
            "Training Accuracy: 69.84%\n",
            "training right now\n",
            "Training Loss: 0.1422\n",
            "Training Accuracy: 69.84%\n",
            "training right now\n",
            "Training Loss: 0.1422\n",
            "Training Accuracy: 69.84%\n",
            "training right now\n",
            "Training Loss: 0.1423\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1423\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1423\n",
            "Training Accuracy: 69.84%\n",
            "training right now\n",
            "Training Loss: 0.1423\n",
            "Training Accuracy: 69.84%\n",
            "training right now\n",
            "Training Loss: 0.1424\n",
            "Training Accuracy: 69.84%\n",
            "training right now\n",
            "Training Loss: 0.1424\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1424\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1424\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1425\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1425\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1425\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1425\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1425\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1426\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1426\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1426\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1426\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1427\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1427\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1427\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1427\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1428\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1428\n",
            "Training Accuracy: 69.86%\n",
            "training right now\n",
            "Training Loss: 0.1428\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1428\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1428\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1429\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1429\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1429\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1429\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1430\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1430\n",
            "Training Accuracy: 69.86%\n",
            "training right now\n",
            "Training Loss: 0.1430\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1430\n",
            "Training Accuracy: 69.85%\n",
            "training right now\n",
            "Training Loss: 0.1430\n",
            "Training Accuracy: 69.86%\n",
            "training right now\n",
            "Training Loss: 0.1431\n",
            "Training Accuracy: 69.86%\n",
            "training right now\n",
            "Training Loss: 0.1431\n",
            "Training Accuracy: 69.86%\n",
            "training right now\n",
            "Training Loss: 0.1431\n",
            "Training Accuracy: 69.86%\n",
            "training right now\n",
            "Training Loss: 0.1432\n",
            "Training Accuracy: 69.86%\n",
            "training right now\n",
            "Training Loss: 0.1432\n",
            "Training Accuracy: 69.86%\n",
            "training right now\n",
            "Training Loss: 0.1432\n",
            "Training Accuracy: 69.86%\n",
            "training right now\n",
            "Training Loss: 0.1432\n",
            "Training Accuracy: 69.86%\n",
            "training right now\n",
            "Training Loss: 0.1432\n",
            "Training Accuracy: 69.86%\n",
            "training right now\n",
            "Training Loss: 0.1433\n",
            "Training Accuracy: 69.86%\n",
            "training right now\n",
            "Training Loss: 0.1433\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1433\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1433\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1433\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1433\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1434\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1434\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1434\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1435\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1435\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1435\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1435\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1435\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1436\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1436\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1436\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1436\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1436\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1437\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1437\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1437\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1437\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1437\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1438\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1438\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1438\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1439\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1439\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1439\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1439\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1440\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1440\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1440\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1440\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1440\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1441\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1441\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1441\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1441\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1442\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1442\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1442\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1443\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1443\n",
            "Training Accuracy: 69.87%\n",
            "training right now\n",
            "Training Loss: 0.1443\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1443\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1443\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1444\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1444\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1444\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1444\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1444\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1445\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1445\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1445\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1445\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1446\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1446\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1446\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1446\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1447\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1447\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1447\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1447\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1448\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1448\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1448\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1448\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1449\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1449\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1449\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1449\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1450\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1450\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1450\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1450\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1450\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1451\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1451\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1451\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1452\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1452\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1452\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1452\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1452\n",
            "Training Accuracy: 69.88%\n",
            "training right now\n",
            "Training Loss: 0.1453\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1453\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1453\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1454\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1454\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1454\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1454\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1455\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1455\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1455\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1455\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1455\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1455\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1456\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1456\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1456\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1456\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1457\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1457\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1457\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1457\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1457\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1458\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1458\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1458\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1458\n",
            "Training Accuracy: 69.89%\n",
            "training right now\n",
            "Training Loss: 0.1458\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1459\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1459\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1459\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1459\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1459\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1459\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1460\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1460\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1460\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1460\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1460\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1460\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1461\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1461\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1461\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1462\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1462\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1462\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1462\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1463\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1463\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1463\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1463\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1463\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1464\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1464\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1464\n",
            "Training Accuracy: 69.90%\n",
            "training right now\n",
            "Training Loss: 0.1464\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1465\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1465\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1465\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1466\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1466\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1466\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1466\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1466\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1467\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1467\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1467\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1468\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1468\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1468\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1468\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1469\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1469\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1469\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1469\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1470\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1470\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1471\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1471\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1471\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1471\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1471\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1472\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1472\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1472\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1472\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1473\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1473\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1473\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1473\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1474\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1474\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1474\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1474\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1475\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1475\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1475\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1475\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1475\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1475\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1476\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1476\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1476\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1476\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1476\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1477\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1477\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1477\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1477\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1478\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1478\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1478\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1479\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1479\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1479\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1480\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1480\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1481\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1481\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1481\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1481\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1482\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1482\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1482\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1482\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1482\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1483\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1483\n",
            "Training Accuracy: 69.91%\n",
            "training right now\n",
            "Training Loss: 0.1483\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1484\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1484\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1484\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1484\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1485\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1485\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1485\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1485\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1486\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1486\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1486\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1486\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1487\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1487\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1487\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1488\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1488\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1488\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1488\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1488\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1489\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1489\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1489\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1489\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1489\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1489\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1490\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1490\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1490\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1490\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1491\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1491\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1491\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1491\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1491\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1492\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1492\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1492\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1492\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1492\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1493\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1493\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1493\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1493\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1494\n",
            "Training Accuracy: 69.92%\n",
            "training right now\n",
            "Training Loss: 0.1494\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1494\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1494\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1494\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1495\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1495\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1495\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1495\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1495\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1496\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1496\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1496\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1496\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1496\n",
            "Training Accuracy: 69.93%\n",
            "training right now\n",
            "Training Loss: 0.1496\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1497\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1497\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1497\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1497\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1497\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1498\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1498\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1498\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1498\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1498\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1499\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1499\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1499\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1500\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1500\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1500\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1500\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1501\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1501\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1501\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1501\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1502\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1502\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1502\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1502\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1503\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1503\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1503\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1503\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1504\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1504\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1504\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1505\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1505\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1505\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1505\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1505\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1505\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1505\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1506\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1506\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1506\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1507\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1507\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1507\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1507\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1508\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1508\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1508\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1508\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1509\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1509\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1509\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1509\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1510\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1510\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1510\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1510\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1511\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1511\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1511\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1511\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1511\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1512\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1512\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1512\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1512\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1512\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1513\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1513\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1513\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1513\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1513\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1514\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1514\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1514\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1515\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1515\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1515\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1515\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1515\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1515\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1516\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1516\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1516\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1516\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1517\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1517\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1517\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1517\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1517\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1518\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1518\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1518\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1519\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1519\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1519\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1519\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1519\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1520\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1520\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1520\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1520\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1520\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1520\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1521\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1521\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1521\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1521\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1521\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1522\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1522\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1522\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1522\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1523\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1523\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1523\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1523\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1523\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1524\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1524\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1524\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1524\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1524\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1525\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1525\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1525\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1525\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1525\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1526\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1526\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1526\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1526\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1527\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1527\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1527\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1527\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1527\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1527\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1528\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1528\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1528\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1528\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1529\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1529\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1529\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1529\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1529\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1530\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1530\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1530\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1531\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1531\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1531\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1531\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1531\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1532\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1532\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1532\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1532\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1532\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1532\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1533\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1533\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1533\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1533\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1533\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1533\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1534\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1534\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1534\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1534\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1535\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1535\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1535\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1536\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1536\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1537\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1537\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1537\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1537\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1538\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1538\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1538\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1539\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1539\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1539\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1539\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1539\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1540\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1540\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1540\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1540\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1540\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1541\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1541\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1542\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1542\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1542\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1543\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1543\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1543\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1544\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1544\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1544\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1544\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1545\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1545\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1545\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1545\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1546\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1546\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1546\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1546\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1546\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1546\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1546\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1547\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1547\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1547\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1548\n",
            "Training Accuracy: 69.94%\n",
            "training right now\n",
            "Training Loss: 0.1548\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1548\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1548\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1548\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1548\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1548\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1549\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1549\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1549\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1549\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1549\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1550\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1550\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1550\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1550\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1551\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1551\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1551\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1551\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1551\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1553\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1553\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1554\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1554\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1554\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1554\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1554\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1555\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1555\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1555\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1555\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1555\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1556\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1556\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1556\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1556\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1557\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1557\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1557\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1557\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1558\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1558\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1558\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1558\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1559\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1559\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1559\n",
            "Training Accuracy: 69.95%\n",
            "training right now\n",
            "Training Loss: 0.1559\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1559\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1560\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1560\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1560\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1560\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1560\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1561\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1561\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1561\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1561\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1561\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1561\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1562\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1562\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1562\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1562\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1562\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1562\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1563\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1563\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1563\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1563\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1564\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1564\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1564\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1564\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1564\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1565\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1565\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1566\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1566\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1567\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1567\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1567\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1567\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1567\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1567\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1568\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1568\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1568\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1568\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1568\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1569\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1569\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1569\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1569\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1570\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1570\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1570\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1570\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1571\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1571\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1571\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1571\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1571\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1572\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1572\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1572\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1573\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1573\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1573\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1573\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1574\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1574\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1574\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1574\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1574\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1575\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1575\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1575\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1575\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1575\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1576\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1576\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1576\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1576\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1576\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1576\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1576\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1577\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1577\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1577\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1577\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1578\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1578\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1578\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1578\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1579\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1579\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1579\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1579\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1579\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1579\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1580\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1580\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1580\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1581\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1581\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1581\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1582\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1582\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1582\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1582\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1583\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1583\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1583\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1583\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1584\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1584\n",
            "Training Accuracy: 69.96%\n",
            "training right now\n",
            "Training Loss: 0.1584\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1584\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1584\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1584\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1585\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1585\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1585\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1585\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1586\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1586\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1586\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1586\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1586\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1587\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1587\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1587\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1587\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1587\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1588\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1588\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1588\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1589\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1589\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1589\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1590\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1590\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1590\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1590\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1590\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1590\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1591\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1591\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1591\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1592\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1592\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1592\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1593\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1593\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1593\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1594\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1594\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1594\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1594\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1595\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1595\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1595\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1596\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1596\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1596\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1596\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1596\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1597\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1597\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1597\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1598\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1598\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1598\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1598\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1599\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1599\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1599\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1599\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1600\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1600\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1601\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1601\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1601\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1601\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1601\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1602\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1602\n",
            "Training Accuracy: 69.97%\n",
            "training right now\n",
            "Training Loss: 0.1602\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1602\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1603\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1603\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1603\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1603\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1604\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1604\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1604\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1604\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1605\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1605\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1605\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1605\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1606\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1606\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1606\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1606\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1607\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1607\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1607\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1607\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1608\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1608\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1608\n",
            "Training Accuracy: 69.98%\n",
            "training right now\n",
            "Training Loss: 0.1608\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1608\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1609\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1609\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1609\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1609\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1609\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1610\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1610\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1610\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1610\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1611\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1611\n",
            "Training Accuracy: 69.99%\n",
            "training right now\n",
            "Training Loss: 0.1611\n",
            "Training Accuracy: 70.00%\n",
            "training right now\n",
            "Training Loss: 0.1611\n",
            "Training Accuracy: 70.00%\n",
            "training right now\n",
            "Training Loss: 0.1611\n",
            "Training Accuracy: 70.00%\n",
            "training right now\n",
            "Training Loss: 0.1612\n",
            "Training Accuracy: 70.00%\n",
            "training right now\n",
            "Training Loss: 0.1612\n",
            "Training Accuracy: 70.00%\n",
            "training right now\n",
            "Training Loss: 0.1612\n",
            "Training Accuracy: 70.00%\n",
            "training right now\n",
            "Training Loss: 0.1612\n",
            "Training Accuracy: 70.00%\n",
            "training right now\n",
            "Training Loss: 0.1612\n",
            "Training Accuracy: 70.00%\n",
            "training right now\n",
            "Training Loss: 0.1612\n",
            "Training Accuracy: 70.00%\n",
            "training right now\n",
            "Training Loss: 0.1613\n",
            "Training Accuracy: 70.00%\n",
            "training right now\n",
            "Training Loss: 0.1613\n",
            "Training Accuracy: 70.01%\n",
            "training right now\n",
            "Training Loss: 0.1613\n",
            "Training Accuracy: 70.01%\n",
            "training right now\n",
            "Training Loss: 0.1613\n",
            "Training Accuracy: 70.01%\n",
            "training right now\n",
            "Training Loss: 0.1613\n",
            "Training Accuracy: 70.01%\n",
            "training right now\n",
            "Training Loss: 0.1613\n",
            "Training Accuracy: 70.01%\n",
            "training right now\n",
            "Training Loss: 0.1613\n",
            "Training Accuracy: 70.01%\n",
            "training right now\n",
            "Training Loss: 0.1614\n",
            "Training Accuracy: 70.01%\n",
            "training right now\n",
            "Training Loss: 0.1614\n",
            "Training Accuracy: 70.01%\n",
            "training right now\n",
            "Training Loss: 0.1614\n",
            "Training Accuracy: 70.01%\n",
            "training right now\n",
            "Training Loss: 0.1614\n",
            "Training Accuracy: 70.01%\n",
            "training right now\n",
            "Training Loss: 0.1615\n",
            "Training Accuracy: 70.01%\n",
            "training right now\n",
            "Training Loss: 0.1615\n",
            "Training Accuracy: 70.01%\n",
            "training right now\n",
            "Training Loss: 0.1615\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1615\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1615\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1615\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1616\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1616\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1616\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1616\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1617\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1617\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1617\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1617\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1618\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1618\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1618\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1619\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1619\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1619\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1620\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1620\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1620\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1620\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1620\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1621\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1621\n",
            "Training Accuracy: 70.02%\n",
            "training right now\n",
            "Training Loss: 0.1621\n",
            "Training Accuracy: 70.03%\n",
            "training right now\n",
            "Training Loss: 0.1621\n",
            "Training Accuracy: 70.03%\n",
            "training right now\n",
            "Training Loss: 0.1621\n",
            "Training Accuracy: 70.03%\n",
            "training right now\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "KQixkmEvniDM",
        "outputId": "9611fb99-4a1c-4307-a13e-68b938b92aa0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sahilc/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/home/sahilc/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/tmp/ipykernel_16916/3924153926.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/home/sahilc/Sports-Analysis/Jersey Number Recognition/best_jersey_model (1).pth'))\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## Test the model on any random image\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load the model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m JerseyNumberNet(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m55\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/sahilc/Sports-Analysis/Jersey Number Recognition/best_jersey_model (1).pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      9\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/sahilc/Sports-Analysis/Jersey Number Recognition/train/images/1/1_15.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/serialization.py:1097\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1095\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1096\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1097\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1105\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/serialization.py:1525\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# Needed for tensors where storage device and rebuild tensor device are\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# not connected (wrapper subclasses and tensors rebuilt using numpy)\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location \u001b[38;5;241m=\u001b[39m map_location\n\u001b[0;32m-> 1525\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_thread_local_state\u001b[38;5;241m.\u001b[39mmap_location\n\u001b[1;32m   1528\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/serialization.py:1492\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1491\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1492\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/serialization.py:1466\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1461\u001b[0m         storage\u001b[38;5;241m.\u001b[39mbyteswap(dtype)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1465\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1466\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1467\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1468\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1471\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/serialization.py:414\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 414\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/serialization.py:391\u001b[0m, in \u001b[0;36m_deserialize\u001b[0;34m(backend_name, obj, location)\u001b[0m\n\u001b[1;32m    389\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_privateuse1_backend_name()\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(backend_name):\n\u001b[0;32m--> 391\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/serialization.py:364\u001b[0m, in \u001b[0;36m_validate_device\u001b[0;34m(location, backend_name)\u001b[0m\n\u001b[1;32m    362\u001b[0m     device_index \u001b[38;5;241m=\u001b[39m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01mif\u001b[39;00m device\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_available\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m device_module\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    365\u001b[0m                        \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    366\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    367\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    368\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(device_module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice_count\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    370\u001b[0m     device_count \u001b[38;5;241m=\u001b[39m device_module\u001b[38;5;241m.\u001b[39mdevice_count()\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
          ]
        }
      ],
      "source": [
        "\n",
        "## Test the model on any random image\n",
        "\n",
        "# Load the model\n",
        "\n",
        "model = JerseyNumberNet(num_classes=55)\n",
        "model.load_state_dict(torch.load('/home/sahilc/Sports-Analysis/Jersey Number Recognition/best_jersey_model (1).pth'))\n",
        "model.eval()\n",
        "\n",
        "image_path = '/home/sahilc/Sports-Analysis/Jersey Number Recognition/train/images/1/1_15.jpg'\n",
        "image = Image.open(image_path).convert('RGB')\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "image = transform(image)\n",
        "image = image.unsqueeze(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "    _, predicted = torch.max(output.data, 1)\n",
        "\n",
        "print(f\"Predicted jersey number: {predicted.item()}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Nqw1wmDrpDpL",
        "outputId": "29f07597-5e46-4c18-b28b-599531bef651"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'image_path' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-5e06a51272a2>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Open the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Display the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image_path' is not defined"
          ]
        }
      ],
      "source": [
        "## view the image to confirm\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Open the image\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
