{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal of this pipeline:\n",
    "Goal of this pipeline is simple! So far, we have trained two models to detect:\n",
    "1. Players, Referees, Balls, GoalKeepers\n",
    "2. Number in the jersey\n",
    "\n",
    "Now, the idea is to merge these two model to get a video where the players are being tracked and provided with jersey number as their id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import supervision as sv\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the model for jersey number recognizer\n",
    "class JerseyNumberNet(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(JerseyNumberNet, self).__init__()\n",
    "\n",
    "        # Use ResNet18 as the base model\n",
    "        self.backbone = models.resnet18(pretrained=pretrained)\n",
    "\n",
    "        # Replace the classification head\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 100)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "class JerseyNumberRecognizer:\n",
    "    def __init__(self, model_path = None, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        self.model = JerseyNumberNet().to(device)\n",
    "\n",
    "        if model_path:\n",
    "            self.model.load_state_dict(torch.load(model_path))\n",
    "            self.model.eval()\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((128, 64)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def train(self, train_loader, val_loader, epochs=5, save_path='best_model.pth'):\n",
    "        \"\"\"Train the model using the given data loaders.\"\"\"\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "\n",
    "        best_accuracy = 0\n",
    "\n",
    "        # for debug purposes:\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            print(f\"Inputs shape: {inputs.shape}\")\n",
    "            print(f\"Labels shape: {labels.shape}\")\n",
    "            \n",
    "            result = self.model(inputs)\n",
    "            print(f\"Result shape: {result.shape}\")\n",
    "            break\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(train_loader):\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 100 == 99:\n",
    "                    print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100}\")\n",
    "                    running_loss = 0.0\n",
    "\n",
    "            self.model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    inputs, labels = data\n",
    "                    inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "\n",
    "                    outputs = self.model(inputs)\n",
    "\n",
    "                    # Convert one-hot encoded labels to class indices\n",
    "                    labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "                    # debug: Print the shape of tensors\n",
    "                    \n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                    total += labels.size(0)\n",
    "                    print(f\"labels: {labels}\")\n",
    "                    print(f\"predicted: {predicted}\")\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "                    print(f\"Total: {total}, Correct: {correct} for epoch {epoch + 1} in validation\")\n",
    "\n",
    "            accuracy = correct / total\n",
    "            print(f\"Accuracy after epoch {epoch + 1}: {accuracy}\")\n",
    "\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                torch.save(self.model.state_dict(), save_path)\n",
    "\n",
    "            scheduler.step()\n",
    "        print(f\"Training finished. Best accuracy: {best_accuracy}\")\n",
    "\n",
    "    def predict(self, jersey_crop: np.ndarray) -> Tuple[int, float]:\n",
    "        \"\"\"Predict the jersey number from the given crop.\"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        image = Image.fromarray(cv2.cvtColor(jersey_crop, cv2.COLOR_BGR2RGB))\n",
    "        image = self.transform(image).unsqueeze(0).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image)\n",
    "            probabilities = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "            prediction = torch.argmax(outputs).item()\n",
    "            confidence = probabilities[0, prediction]\n",
    "\n",
    "        return prediction, confidence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_detector_weights = 'yolov5s.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import supervision as sv\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "class PlayerJerseyTracker:\n",
    "    def __init__(\n",
    "        self,\n",
    "        object_detector_weights: str,\n",
    "        jersey_model_weights: str,\n",
    "        conf_threshold: float = 0.5,\n",
    "        jersey_conf_threshold: float = 0.7,\n",
    "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    ):\n",
    "        \"\"\"Initialize the player tracking pipeline with jersey recognition\"\"\"\n",
    "        self.device = device\n",
    "        self.conf_threshold = conf_threshold\n",
    "        self.jersey_conf_threshold = jersey_conf_threshold\n",
    "        \n",
    "        # Initialize models\n",
    "        self.object_detector = YOLO(object_detector_weights)\n",
    "        self.jersey_recognizer = JerseyNumberRecognizer(\n",
    "            model_path=jersey_model_weights,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        # Initialize tracker\n",
    "        self.tracker = sv.ByteTrack()\n",
    "        self.tracker.reset()\n",
    "        \n",
    "        # Player tracking history\n",
    "        self.player_history = defaultdict(lambda: {\n",
    "            'jersey_numbers': [],\n",
    "            'confidences': [],\n",
    "            'frames_visible': 0,\n",
    "            'last_seen': 0,\n",
    "            'most_common_number': -1\n",
    "        })\n",
    "        \n",
    "        # Initialize annotators\n",
    "        self.box_annotator = sv.BoxAnnotator(\n",
    "            color=sv.ColorPalette.default(),\n",
    "            thickness=2\n",
    "        )\n",
    "        self.label_annotator = sv.LabelAnnotator(\n",
    "            color=sv.ColorPalette.default(),\n",
    "            text_color=sv.Color.black(),\n",
    "            text_position=sv.Position.BOTTOM_CENTER\n",
    "        )\n",
    "        \n",
    "    def get_jersey_number(self, frame: np.ndarray, bbox: List[int]) -> Tuple[int, float]:\n",
    "        \"\"\"Extract and recognize jersey number from player bbox\"\"\"\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        h = y2 - y1\n",
    "        w = x2 - x1\n",
    "        \n",
    "        # Extract upper body region\n",
    "        jersey_y1 = max(0, y1 + int(h * 0.15))\n",
    "        jersey_y2 = min(frame.shape[0], y1 + int(h * 0.5))\n",
    "        jersey_x1 = max(0, x1)\n",
    "        jersey_x2 = min(frame.shape[1], x2)\n",
    "        \n",
    "        jersey_crop = frame[jersey_y1:jersey_y2, jersey_x1:jersey_x2]\n",
    "        \n",
    "        if jersey_crop.size == 0:\n",
    "            return -1, 0.0\n",
    "        \n",
    "        number, confidence = self.jersey_recognizer.predict(jersey_crop)\n",
    "        return number, confidence\n",
    "\n",
    "    def update_player_history(self, track_id: int, jersey_number: int, \n",
    "                            confidence: float, frame_id: int):\n",
    "        \"\"\"Update player tracking history\"\"\"\n",
    "        history = self.player_history[track_id]\n",
    "        history['jersey_numbers'].append(jersey_number)\n",
    "        history['confidences'].append(confidence)\n",
    "        history['frames_visible'] += 1\n",
    "        history['last_seen'] = frame_id\n",
    "        \n",
    "        # Update most common jersey number if confidence is high enough\n",
    "        if confidence > self.jersey_conf_threshold:\n",
    "            numbers = [n for n, c in zip(history['jersey_numbers'], history['confidences'])\n",
    "                      if c > self.jersey_conf_threshold]\n",
    "            \n",
    "            if numbers:\n",
    "                from collections import Counter\n",
    "                counter = Counter(numbers)\n",
    "                history['most_common_number'] = counter.most_common(1)[0][0]\n",
    "\n",
    "    def process_frame(self, frame: np.ndarray, frame_id: int) -> Tuple[List[Dict], np.ndarray]:\n",
    "        \"\"\"Process a single frame with tracking and jersey number recognition\"\"\"\n",
    "        # Run detection\n",
    "        results = self.object_detector(frame, conf=self.conf_threshold)[0]\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "        \n",
    "        # Apply NMS\n",
    "        detections = detections.with_nms(threshold=0.5)\n",
    "        \n",
    "        # Separate players from other detections\n",
    "        player_mask = detections.class_id == 1  # Assuming class_id 1 is for players\n",
    "        player_detections = detections[player_mask]\n",
    "        \n",
    "        # Update tracker\n",
    "        tracked_players = self.tracker.update_with_detections(player_detections)\n",
    "        \n",
    "        # Process jersey numbers for tracked players\n",
    "        for i in range(len(tracked_players)):\n",
    "            if tracked_players.tracker_id is not None:\n",
    "                track_id = tracked_players.tracker_id[i]\n",
    "                bbox = tracked_players.xyxy[i]\n",
    "                \n",
    "                # Get jersey number\n",
    "                number, conf = self.get_jersey_number(frame, bbox)\n",
    "                \n",
    "                # Update history\n",
    "                self.update_player_history(track_id, number, conf, frame_id)\n",
    "                \n",
    "                # Add jersey number to annotations\n",
    "                jersey_num = self.player_history[track_id]['most_common_number']\n",
    "                if jersey_num != -1:\n",
    "                    tracked_players.add_annotation(\n",
    "                        annotation_type=\"jersey_number\",\n",
    "                        value=jersey_num,\n",
    "                        index=i\n",
    "                    )\n",
    "        \n",
    "        # Prepare frame annotation\n",
    "        annotated_frame = frame.copy()\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        labels = [\n",
    "            f\"#{track_id} \" +\n",
    "            (f\"Jersey #{self.player_history[track_id]['most_common_number']}\"\n",
    "             if self.player_history[track_id]['most_common_number'] != -1 else \"\")\n",
    "            for track_id in tracked_players.tracker_id\n",
    "        ]\n",
    "        \n",
    "        annotated_frame = self.box_annotator.annotate(\n",
    "            scene=annotated_frame, \n",
    "            detections=tracked_players\n",
    "        )\n",
    "        \n",
    "        annotated_frame = self.label_annotator.annotate(\n",
    "            scene=annotated_frame,\n",
    "            detections=tracked_players,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        return tracked_players, annotated_frame\n",
    "\n",
    "    def process_video(\n",
    "        self,\n",
    "        source_path: str,\n",
    "        output_path: str,\n",
    "        start_frame: int = 0,\n",
    "        end_frame: int = None\n",
    "    ):\n",
    "        \"\"\"Process video with player tracking and jersey number recognition\"\"\"\n",
    "        # Get video info\n",
    "        video_info = sv.VideoInfo.from_video_path(source_path)\n",
    "        \n",
    "        if end_frame is None:\n",
    "            end_frame = video_info.total_frames\n",
    "            \n",
    "        # Initialize video writer\n",
    "        video_sink = sv.VideoSink(\n",
    "            output_path,\n",
    "            video_info\n",
    "        )\n",
    "        \n",
    "        # Process frames\n",
    "        frame_generator = sv.get_video_frames_generator(source_path)\n",
    "        \n",
    "        with video_sink:\n",
    "            for frame_idx, frame in enumerate(frame_generator):\n",
    "                if frame_idx < start_frame:\n",
    "                    continue\n",
    "                if frame_idx >= end_frame:\n",
    "                    break\n",
    "                    \n",
    "                try:\n",
    "                    # Process frame\n",
    "                    detections, annotated_frame = self.process_frame(\n",
    "                        frame, frame_idx\n",
    "                    )\n",
    "                    \n",
    "                    # Write frame\n",
    "                    video_sink.write_frame(annotated_frame)\n",
    "                    \n",
    "                    # Show progress\n",
    "                    if frame_idx % 30 == 0:\n",
    "                        print(f\"Processed frame {frame_idx}/{end_frame}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing frame {frame_idx}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        return self.player_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize tracker\n",
    "    tracker = PlayerJerseyTracker(\n",
    "        object_detector_weights=\"path/to/yolo_weights.pt\",\n",
    "        jersey_model_weights=\"path/to/jersey_model.pt\",\n",
    "        conf_threshold=0.5,\n",
    "        jersey_conf_threshold=0.7\n",
    "    )\n",
    "    \n",
    "    # Process video\n",
    "    history = tracker.process_video(\n",
    "        source_path=\"input_video.mp4\",\n",
    "        output_path=\"output_video.mp4\"\n",
    "    )\n",
    "    \n",
    "    # Print tracking statistics\n",
    "    print(\"\\nPlayer Tracking Statistics:\")\n",
    "    for track_id, data in history.items():\n",
    "        if data['most_common_number'] != -1:\n",
    "            print(f\"\\nPlayer #{track_id}\")\n",
    "            print(f\"Jersey Number: {data['most_common_number']}\")\n",
    "            print(f\"Frames Visible: {data['frames_visible']}\")\n",
    "            print(f\"Average Confidence: {np.mean(data['confidences']):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
