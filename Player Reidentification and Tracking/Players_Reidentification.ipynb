{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal of this pipeline:\n",
    "Goal of this pipeline is simple! So far, we have trained two models to detect:\n",
    "1. Players, Referees, Balls, GoalKeepers\n",
    "2. Number in the jersey\n",
    "\n",
    "Now, the idea is to merge these two model to get a video where the players are being tracked and provided with jersey number as their id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from typing import Dict, List, Tuple\n",
    "from torchvision import transforms, models\n",
    "import YOLO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the model to detect objects\n",
    "\n",
    "detector_path = 'models/faster_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb'\n",
    "number_classifier_path = 'models/number_classifier.pb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class to identify players by their jersey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2678833978.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 16\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"Extract jersey region from the player detection\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class PlayerIdentifier:\n",
    "    \"\"\"We have two models, one for detecting objects and one for classifying numbers. The model for classifying numbers has been trained on cropped image and hence we need to find the bounding box of the numbers in the image first and then use the number identifier on these bounding boxed image\"\"\"\n",
    "    def __init__(self, object_detector_weights: str, number_classifier_weights: str, confidence_threshold: float = 0.5, device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.device = device\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "\n",
    "        # Load the object detector model    \n",
    "        self.object_detector = YOLO(object_detector_weights).to(self.device)\n",
    "\n",
    "        # Load the number classifier model based on RESNET 18 model\n",
    "        self.jersey_recognizer = JerseyNumberRecognizer(number_classifier_weights).to(self.device)\n",
    "\n",
    "        self.class_names = ['player', 'referee', 'goalkeeper', 'ball']\n",
    "\n",
    "    def extract_jersey_region(self, frame: np.ndarray, bbox: List[float], padding: float=0.1)-> np.ndarray:\n",
    "        \"\"\"Extract jersey region from the player detection\"\"\"\n",
    "\n",
    "        # Extract the bounding box\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        h = y2 - y1\n",
    "        w = x2 - x1\n",
    "\n",
    "        # Add padding to the bounding box\n",
    "        pad_x = int(padding * w)\n",
    "        pad_y = int(padding * h)\n",
    "\n",
    "        x1 = max(0, x1 - pad_x)\n",
    "        x2 = min(frame.shape[1], x2 + pad_x)\n",
    "        y1 = max(0, y1 - pad_y)\n",
    "        y2 = min(frame.shape[0], y2 + pad_y)\n",
    "\n",
    "        return frame[y1:y2, x1:x2] \n",
    "    \n",
    "    def process_frame(self, frame: np.ndarrya, draw: bool = False) -> Tuple[List[Dict], np.ndarray]:\n",
    "        \"\"\" Process a single frame to return the list of detections with jersey numbers\"\"\"\n",
    "        results = self.object_detector(frame)\n",
    "        detections = []\n",
    "        results = results[0]\n",
    "        # Draw bounding boxes\n",
    "        boxes = results.boxes.xyxy.cpu().numpy()\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = box\n",
    "            class_id = int(cls)\n",
    "            \n",
    "            if class_id == 0: # player class\n",
    "                jersey_region = self.extract_jersey_region(frame, [x1, y1, x2, y2 ])\n",
    "                \n",
    "                if jersey_region is not None:\n",
    "                    number, number_conf = self.jersey_recognizer.predict(jersey_region)\n",
    "                else:\n",
    "                    number = -1\n",
    "                    number_conf = 0.0\n",
    "\n",
    "                detection = {\n",
    "                    'class': self.class_names[class_id],\n",
    "                    'bbox': [x1, y1, x2, y2],\n",
    "                    'number': number,\n",
    "                    'number_conf': number_conf,\n",
    "                    'Jersey_number': int(number)\n",
    "                }\n",
    "            else:\n",
    "                detection = {\n",
    "                    'class': self.class_names[class_id],\n",
    "                    'bbox': [x1, y1, x2, y2],\n",
    "                    'confidence': conf\n",
    "                }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
